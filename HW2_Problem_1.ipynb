{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2 Problem 1",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DolT7dwYyKg1"
      },
      "source": [
        "# HW2 - Problem 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wDEyKGjVz20f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1gmd1PhHyo8P"
      },
      "outputs": [],
      "source": [
        "class Graph:\n",
        "  \"\"\"\n",
        "  Turns a numpy image into a graph\n",
        "  Allows for finding connected components\n",
        "  \"\"\"\n",
        "  # Choose an arbitrary value to be what we consider \"on\"\n",
        "\n",
        "  def pixel_round(self, num):\n",
        "    return int(num >= 100)\n",
        "  # init function to declare class variables \n",
        "  def __init__(self, image):\n",
        "    # First, create the graph from the image \n",
        "    self.V = len(image) * len(image[0])\n",
        "    self.adj = []\n",
        "\n",
        "    v = 0\n",
        "    for i in range(len(image)):\n",
        "      for j in range(len(image[i])):\n",
        "        new_ad = []\n",
        "        if j > 0 and (self.pixel_round(image[i, j]) == self.pixel_round(image[i, j - 1])):\n",
        "          new_ad.append(v - 1)\n",
        "        if j < len(image[i]) - 1 and (self.pixel_round(image[i, j]) == self.pixel_round(image[i, j + 1])):\n",
        "          new_ad.append(v + 1)\n",
        "        if i > 0 and (self.pixel_round(image[i, j]) == self.pixel_round(image[i - 1, j])):\n",
        "          new_ad.append(v - len(image[i]))\n",
        "        if i < len(image) - 1 and (self.pixel_round(image[i, j]) == self.pixel_round(image[i + 1, j])):\n",
        "          new_ad.append(v + len(image[i]))\n",
        "        \n",
        "        # Apend the new adjacency list\n",
        "        self.adj.append(new_ad)\n",
        "        v += 1\n",
        "  \n",
        "  def boundedDFS(self, temp, v, visited): \n",
        "    \"\"\"\n",
        "    DFS until you've encountered either a visited node\n",
        "    \"\"\"\n",
        "  \n",
        "    # Visit the current v\n",
        "    visited[v] = True\n",
        "  \n",
        "    # store it\n",
        "    temp.append(v) \n",
        "  \n",
        "    # repeat for everything adjacent to v\n",
        "    for i in self.adj[v]: \n",
        "      if visited[i] == False: \n",
        "        # Update the list \n",
        "        temp = self.boundedDFS(temp, i, visited) \n",
        "    return temp \n",
        "  \n",
        "  # method to add an undirected edge \n",
        "  def addEdge(self, v, w): \n",
        "    self.adj[v].append(w) \n",
        "    self.adj[w].append(v) \n",
        "        \n",
        "  def connectedComponents(self):\n",
        "    \"\"\"\n",
        "    Use DFS to find all connected components\n",
        "    \"\"\"\n",
        "    visited = [] \n",
        "    cc = [] \n",
        "    for i in range(self.V): \n",
        "      visited.append(False) \n",
        "    for v in range(self.V): \n",
        "      if visited[v] == False: \n",
        "        temp = [] \n",
        "        new_cc = self.boundedDFS(temp, v, visited) \n",
        "        if len(new_cc) > 1:\n",
        "          cc.append(new_cc)\n",
        "    return cc \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WgxtvByO0Lvu"
      },
      "source": [
        "Our stratgy to build our handcrafted features is as follows:\n",
        "We first turn the image into a graph, then use DFS to find all connected components\n",
        "Once we have the number of said components, we find the component corresponding to the image itself and find the width and height by comparing its maximum and minimum elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "rfDbu8woyAcx"
      },
      "outputs": [],
      "source": [
        "def features(image):\n",
        "  \"\"\"\n",
        "  Given an mnist image, returns the number of connected componants, the height,\n",
        "  and the width of that image\n",
        "  \"\"\"\n",
        "  image = np.array(image)\n",
        "  g = Graph(image)\n",
        "  cc = g.connectedComponents()\n",
        "    \n",
        "  # Search for the connected component that actually makes up the ones \n",
        "    \n",
        "  for comp in cc:\n",
        "    if image[comp[0] // 28, comp[0] % 28] != 0:\n",
        "      true_num = np.array(comp)\n",
        "      break\n",
        "\n",
        "  # Get the horizontal position of pixals\n",
        "  hor_pos = np.mod(true_num, 28)\n",
        "  \n",
        "  # simply find the pixel furthest to the left, and the one furthest to the right\n",
        "  left = np.min(hor_pos)\n",
        "  right = np.max(hor_pos)\n",
        "  width = right - left\n",
        "    \n",
        "  # Get the vertical position of pixals\n",
        "  vert_pos = true_num // 28\n",
        "    \n",
        "  ## Same as before, just vertical\n",
        "  top = np.min(vert_pos)\n",
        "  bottom = np.max(vert_pos)\n",
        "  height = bottom - top\n",
        "    \n",
        "  return np.array([len(cc), height / 10, width / 10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0SPsX99AyC7l"
      },
      "outputs": [],
      "source": [
        "mnist = keras.datasets.mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "KQqM7YLV0IEi"
      },
      "outputs": [],
      "source": [
        "train_images = np.concatenate([features(d) for d in train_images])\n",
        "test_images = np.concatenate([features(d) for d in test_images])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "bSDj1yzd1Qel"
      },
      "outputs": [],
      "source": [
        "train_labels = keras.utils.to_categorical(train_labels)\n",
        "test_labels = keras.utils.to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8tTOP6Gc2zYC"
      },
      "outputs": [],
      "source": [
        "test_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_images' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1b28d0c2fc13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m history = model.fit(train_images, \n\u001b[0m\u001b[1;32m     21\u001b[0m                       \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
          ]
        }
      ],
      "source": [
        "# set up the layers\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "model = keras.Sequential([\n",
        "\n",
        "    keras.layers.Dense(30, activation=tf.nn.relu, input_shape=(3, )),\n",
        "    keras.layers.Dense(15, activation=tf.nn.relu),\n",
        "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "epochs = 50\n",
        "history = model.fit(train_images, \n",
        "                      train_labels, \n",
        "                      epochs=epochs,  \n",
        "                      validation_data=(test_images, test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gQYw4fIG3XPz"
      },
      "outputs": [],
      "source": []
    }
  ]
}